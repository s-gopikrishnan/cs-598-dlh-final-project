{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "# import glove\n",
    "# from glove import Corpus\n",
    "from mittens import GloVe\n",
    "\n",
    "import collections\n",
    "import gc \n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, merge, Activation, Concatenate, LSTM, GRU\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n",
    "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D, merge\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "from keras.backend.tensorflow_backend import set_session, clear_session, get_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dict_of_ner):\n",
    "    temp_data = []\n",
    "    for k, v in sorted(dict_of_ner.items()):\n",
    "        temp = []\n",
    "        for embed in v:\n",
    "            temp.append(embed)\n",
    "        temp_data.append(np.mean(temp, axis = 0)) \n",
    "    return np.asarray(temp_data)\n",
    "\n",
    "def make_prediction_multi_avg(model, test_data):\n",
    "    probs = model.predict(test_data)\n",
    "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
    "    return probs, y_pred\n",
    "\n",
    "def save_scores_multi_avg(predictions, probs, ground_truth, \n",
    "                          \n",
    "                          embed_name, problem_type, iteration, hidden_unit_size,\n",
    "                          \n",
    "                          sequence_name, type_of_ner):\n",
    "    \n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    result_dict = {}    \n",
    "    result_dict['auc'] = auc\n",
    "    result_dict['auprc'] = auprc\n",
    "    result_dict['acc'] = acc\n",
    "    result_dict['F1'] = F1\n",
    "    \n",
    "    result_path = \"results/\"\n",
    "    file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n",
    "    file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-avg-.p\"\n",
    "    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
    "\n",
    "    print(auc, auprc, acc, F1)\n",
    "    \n",
    "def avg_ner_model(layer_name, number_of_unit, embedding_name):\n",
    "\n",
    "    if embedding_name == \"concat\":\n",
    "        input_dimension = 200\n",
    "    else:\n",
    "        input_dimension = 100\n",
    "\n",
    "    sequence_input = Input(shape=(24,104))\n",
    "\n",
    "    input_avg = Input(shape=(input_dimension, ), name = \"avg\")        \n",
    "#     x_1 = Dense(256, activation='relu')(input_avg)\n",
    "#     x_1 = Dropout(0.3)(x_1)\n",
    "    \n",
    "    if layer_name == \"GRU\":\n",
    "        x = GRU(number_of_unit)(sequence_input)\n",
    "    elif layer_name == \"LSTM\":\n",
    "        x = LSTM(number_of_unit)(sequence_input)\n",
    "\n",
    "    x = keras.layers.Concatenate()([x, input_avg])\n",
    "\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    logits_regularizer = tf.contrib.layers.l2_regularizer(scale=0.01)\n",
    "    \n",
    "    preds = Dense(1, activation='sigmoid',use_bias=False,\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                  kernel_regularizer=logits_regularizer)(x)\n",
    "    \n",
    "    \n",
    "    opt = Adam(lr=0.001, decay = 0.01)\n",
    "    model = Model(inputs=[sequence_input, input_avg], outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_ner = \"new\"\n",
    "\n",
    "x_train_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_train.pkl\")\n",
    "x_dev_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_dev.pkl\")\n",
    "x_test_lstm = pd.read_pickle(\"data/\"+type_of_ner+\"_x_test.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(\"data/\"+type_of_ner+\"_y_train.pkl\")\n",
    "y_dev = pd.read_pickle(\"data/\"+type_of_ner+\"_y_dev.pkl\")\n",
    "y_test = pd.read_pickle(\"data/\"+type_of_ner+\"_y_test.pkl\")\n",
    "\n",
    "ner_word2vec = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_word2vec_limited_dict.pkl\")\n",
    "ner_fasttext = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_fasttext_limited_dict.pkl\")\n",
    "ner_concat = pd.read_pickle(\"data/\"+type_of_ner+\"_ner_combined_limited_dict.pkl\")\n",
    "\n",
    "train_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_train_ids.pkl\")\n",
    "dev_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_dev_ids.pkl\")\n",
    "test_ids = pd.read_pickle(\"data/\"+type_of_ner+\"_test_ids.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_keras(model):\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del model # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    gc.collect() # if it's done something you should see a number being outputted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:  GRU\n",
      "Hidden unit:  128\n",
      "Embedding:  word2vec\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 5s 306us/step - loss: 0.2829 - acc: 0.9024 - val_loss: 0.2392 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23919, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 4s 242us/step - loss: 0.2409 - acc: 0.9145 - val_loss: 0.2363 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23919 to 0.23632, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 4s 249us/step - loss: 0.2295 - acc: 0.9177 - val_loss: 0.2342 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23632 to 0.23422, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 4s 262us/step - loss: 0.2193 - acc: 0.9210 - val_loss: 0.2309 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23422 to 0.23093, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 5s 338us/step - loss: 0.2155 - acc: 0.9232 - val_loss: 0.2319 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23093\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 7s 473us/step - loss: 0.2096 - acc: 0.9233 - val_loss: 0.2355 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23093\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 8s 498us/step - loss: 0.2050 - acc: 0.9250 - val_loss: 0.2344 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23093\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 7s 455us/step - loss: 0.2013 - acc: 0.9270 - val_loss: 0.2345 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23093\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 7s 487us/step - loss: 0.1994 - acc: 0.9265 - val_loss: 0.2358 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23093\n",
      "0.8813166358269451 0.5819320231072123 0.9172033118675254 0.46745562130177515\n",
      "WARNING:tensorflow:From /Users/Gopikrishnan.Srinivasan@ey.com/opt/anaconda3/envs/py3713/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 10s 632us/step - loss: 0.2065 - acc: 0.9347 - val_loss: 0.1762 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17616, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 8s 542us/step - loss: 0.1753 - acc: 0.9433 - val_loss: 0.1694 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17616 to 0.16944, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 8s 540us/step - loss: 0.1653 - acc: 0.9457 - val_loss: 0.1695 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16944\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 8s 558us/step - loss: 0.1581 - acc: 0.9472 - val_loss: 0.1691 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.16944 to 0.16906, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 9s 571us/step - loss: 0.1540 - acc: 0.9472 - val_loss: 0.1689 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16906 to 0.16887, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 9s 598us/step - loss: 0.1488 - acc: 0.9507 - val_loss: 0.1684 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16887 to 0.16840, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 9s 609us/step - loss: 0.1470 - acc: 0.9509 - val_loss: 0.1694 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16840\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 9s 610us/step - loss: 0.1433 - acc: 0.9514 - val_loss: 0.1698 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16840\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 9s 602us/step - loss: 0.1401 - acc: 0.9520 - val_loss: 0.1703 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16840\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 9s 604us/step - loss: 0.1394 - acc: 0.9526 - val_loss: 0.1707 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16840\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 9s 611us/step - loss: 0.1362 - acc: 0.9544 - val_loss: 0.1708 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16840\n",
      "0.8850554801254741 0.5248973988031019 0.9422723091076357 0.4531590413943355\n",
      "Problem type:  los_3\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 11s 740us/step - loss: 0.6799 - acc: 0.6207 - val_loss: 0.6348 - val_acc: 0.6594\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63476, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 11s 701us/step - loss: 0.6341 - acc: 0.6569 - val_loss: 0.6223 - val_acc: 0.6640\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63476 to 0.62232, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 10s 679us/step - loss: 0.6191 - acc: 0.6714 - val_loss: 0.6202 - val_acc: 0.6793\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62232 to 0.62016, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 10s 639us/step - loss: 0.6128 - acc: 0.6736 - val_loss: 0.6167 - val_acc: 0.6696\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62016 to 0.61673, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 10s 674us/step - loss: 0.6035 - acc: 0.6833 - val_loss: 0.6142 - val_acc: 0.6747\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.61673 to 0.61418, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 12s 777us/step - loss: 0.6009 - acc: 0.6843 - val_loss: 0.6163 - val_acc: 0.6793\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.61418\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 14s 914us/step - loss: 0.5982 - acc: 0.6890 - val_loss: 0.6136 - val_acc: 0.6784\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61418 to 0.61358, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 15s 970us/step - loss: 0.5960 - acc: 0.6898 - val_loss: 0.6141 - val_acc: 0.6807\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.61358\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 13s 886us/step - loss: 0.5930 - acc: 0.6933 - val_loss: 0.6132 - val_acc: 0.6807\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.61358 to 0.61323, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 14s 889us/step - loss: 0.5889 - acc: 0.6943 - val_loss: 0.6128 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61323 to 0.61280, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 13s 882us/step - loss: 0.5878 - acc: 0.6977 - val_loss: 0.6122 - val_acc: 0.6835\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61280 to 0.61219, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 12/100\n",
      "15219/15219 [==============================] - 15s 992us/step - loss: 0.5834 - acc: 0.7009 - val_loss: 0.6123 - val_acc: 0.6835\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.61219\n",
      "Epoch 13/100\n",
      "15219/15219 [==============================] - 15s 979us/step - loss: 0.5826 - acc: 0.7021 - val_loss: 0.6123 - val_acc: 0.6811\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.61219\n",
      "Epoch 14/100\n",
      "15219/15219 [==============================] - 14s 943us/step - loss: 0.5802 - acc: 0.7069 - val_loss: 0.6141 - val_acc: 0.6839\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.61219\n",
      "Epoch 15/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.5804 - acc: 0.7063 - val_loss: 0.6139 - val_acc: 0.6798\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.61219\n",
      "Epoch 16/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.5773 - acc: 0.7081 - val_loss: 0.6128 - val_acc: 0.6830\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.61219\n",
      "0.7038416136870773 0.6442563373812928 0.6676632934682613 0.5685279187817259\n",
      "Problem type:  los_7\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.2902 - acc: 0.9164 - val_loss: 0.2640 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26400, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2575 - acc: 0.9203 - val_loss: 0.2607 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26400 to 0.26074, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 18s 1ms/step - loss: 0.2475 - acc: 0.9223 - val_loss: 0.2588 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26074 to 0.25880, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.2434 - acc: 0.9223 - val_loss: 0.2606 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25880\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.2397 - acc: 0.9233 - val_loss: 0.2614 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25880\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.2361 - acc: 0.9223 - val_loss: 0.2608 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25880\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 22s 1ms/step - loss: 0.2350 - acc: 0.9229 - val_loss: 0.2608 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25880\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 22s 1ms/step - loss: 0.2329 - acc: 0.9233 - val_loss: 0.2602 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25880\n",
      "0.734253619598748 0.2210149127675557 0.9188132474701012 0.03287671232876712\n",
      "Embedding:  fasttext\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 25s 2ms/step - loss: 0.2930 - acc: 0.8982 - val_loss: 0.2493 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24926, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.2442 - acc: 0.9129 - val_loss: 0.2436 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24926 to 0.24363, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 27s 2ms/step - loss: 0.2293 - acc: 0.9173 - val_loss: 0.2388 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24363 to 0.23878, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 23s 2ms/step - loss: 0.2217 - acc: 0.9211 - val_loss: 0.2399 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23878\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 22s 1ms/step - loss: 0.2151 - acc: 0.9229 - val_loss: 0.2398 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23878\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 22s 1ms/step - loss: 0.2109 - acc: 0.9242 - val_loss: 0.2394 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23878\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 22s 1ms/step - loss: 0.2075 - acc: 0.9244 - val_loss: 0.2407 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23878\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 22s 1ms/step - loss: 0.2043 - acc: 0.9272 - val_loss: 0.2415 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23878\n",
      "0.8735973433782713 0.5705245847013551 0.9149034038638455 0.44108761329305135\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 25s 2ms/step - loss: 0.2146 - acc: 0.9347 - val_loss: 0.1815 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18149, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.1813 - acc: 0.9402 - val_loss: 0.1788 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18149 to 0.17878, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.1686 - acc: 0.9443 - val_loss: 0.1776 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17878 to 0.17758, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.1632 - acc: 0.9454 - val_loss: 0.1754 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17758 to 0.17542, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 25s 2ms/step - loss: 0.1580 - acc: 0.9472 - val_loss: 0.1757 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17542\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.1524 - acc: 0.9489 - val_loss: 0.1758 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.17542\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 25s 2ms/step - loss: 0.1496 - acc: 0.9493 - val_loss: 0.1750 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.17542 to 0.17502, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 23s 2ms/step - loss: 0.1475 - acc: 0.9508 - val_loss: 0.1757 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17502\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.1446 - acc: 0.9512 - val_loss: 0.1763 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17502\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 20s 1ms/step - loss: 0.1413 - acc: 0.9528 - val_loss: 0.1766 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17502\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.1398 - acc: 0.9535 - val_loss: 0.1769 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17502\n",
      "Epoch 12/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.1379 - acc: 0.9538 - val_loss: 0.1769 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17502\n",
      "0.8849673049612186 0.5219219660731966 0.9404323827046918 0.4332603938730853\n",
      "Problem type:  los_3\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.6918 - acc: 0.6146 - val_loss: 0.6371 - val_acc: 0.6557\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63707, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 14s 925us/step - loss: 0.6391 - acc: 0.6534 - val_loss: 0.6275 - val_acc: 0.6627\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63707 to 0.62751, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 14s 937us/step - loss: 0.6250 - acc: 0.6673 - val_loss: 0.6247 - val_acc: 0.6738\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62751 to 0.62473, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 14s 941us/step - loss: 0.6176 - acc: 0.6723 - val_loss: 0.6218 - val_acc: 0.6770\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62473 to 0.62184, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 14s 942us/step - loss: 0.6120 - acc: 0.6770 - val_loss: 0.6224 - val_acc: 0.6742\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.62184\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 14s 936us/step - loss: 0.6107 - acc: 0.6793 - val_loss: 0.6226 - val_acc: 0.6742\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.62184\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.6058 - acc: 0.6817 - val_loss: 0.6206 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62184 to 0.62058, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.6021 - acc: 0.6864 - val_loss: 0.6206 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.62058\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.5974 - acc: 0.6926 - val_loss: 0.6189 - val_acc: 0.6756\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.62058 to 0.61889, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.5975 - acc: 0.6932 - val_loss: 0.6183 - val_acc: 0.6710\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61889 to 0.61828, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.5944 - acc: 0.6966 - val_loss: 0.6213 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.61828\n",
      "Epoch 12/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.5915 - acc: 0.6943 - val_loss: 0.6186 - val_acc: 0.6779\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.61828\n",
      "Epoch 13/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.5878 - acc: 0.6987 - val_loss: 0.6194 - val_acc: 0.6779\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.61828\n",
      "Epoch 14/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.5877 - acc: 0.6980 - val_loss: 0.6208 - val_acc: 0.6742\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.61828\n",
      "Epoch 15/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.5867 - acc: 0.7008 - val_loss: 0.6208 - val_acc: 0.6714\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.61828\n",
      "0.6984054330514948 0.638828112478699 0.6600735970561178 0.535512256442489\n",
      "Problem type:  los_7\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.2931 - acc: 0.9157 - val_loss: 0.2683 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26831, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 14s 936us/step - loss: 0.2618 - acc: 0.9198 - val_loss: 0.2657 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26831 to 0.26574, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 14s 946us/step - loss: 0.2531 - acc: 0.9211 - val_loss: 0.2647 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26574 to 0.26470, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 15s 963us/step - loss: 0.2461 - acc: 0.9213 - val_loss: 0.2648 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26470\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 14s 932us/step - loss: 0.2455 - acc: 0.9222 - val_loss: 0.2653 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26470\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 14s 927us/step - loss: 0.2390 - acc: 0.9220 - val_loss: 0.2639 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.26470 to 0.26386, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 15s 1ms/step - loss: 0.2375 - acc: 0.9226 - val_loss: 0.2642 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26386\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2350 - acc: 0.9229 - val_loss: 0.2646 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26386\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2332 - acc: 0.9234 - val_loss: 0.2638 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.26386 to 0.26378, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2310 - acc: 0.9228 - val_loss: 0.2637 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.26378 to 0.26368, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2292 - acc: 0.9232 - val_loss: 0.2638 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26368\n",
      "Epoch 12/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2286 - acc: 0.9238 - val_loss: 0.2641 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26368\n",
      "Epoch 13/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2254 - acc: 0.9234 - val_loss: 0.2643 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26368\n",
      "Epoch 14/100\n",
      "15219/15219 [==============================] - 15s 966us/step - loss: 0.2248 - acc: 0.9245 - val_loss: 0.2643 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26368\n",
      "Epoch 15/100\n",
      "15219/15219 [==============================] - 14s 927us/step - loss: 0.2238 - acc: 0.9241 - val_loss: 0.2646 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26368\n",
      "0.7170932454797234 0.21103791790935933 0.9181232750689973 0.0273224043715847\n",
      "Embedding:  concat\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 14s 953us/step - loss: 0.3160 - acc: 0.8951 - val_loss: 0.2478 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24776, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 12s 807us/step - loss: 0.2467 - acc: 0.9127 - val_loss: 0.2371 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24776 to 0.23715, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 12s 805us/step - loss: 0.2344 - acc: 0.9162 - val_loss: 0.2355 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23715 to 0.23552, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 13s 853us/step - loss: 0.2238 - acc: 0.9203 - val_loss: 0.2394 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23552\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 12s 812us/step - loss: 0.2184 - acc: 0.9223 - val_loss: 0.2347 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23552 to 0.23474, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 13s 866us/step - loss: 0.2118 - acc: 0.9244 - val_loss: 0.2343 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.23474 to 0.23435, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 14s 947us/step - loss: 0.2094 - acc: 0.9240 - val_loss: 0.2337 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.23435 to 0.23375, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 15s 974us/step - loss: 0.2032 - acc: 0.9263 - val_loss: 0.2347 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23375\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2003 - acc: 0.9280 - val_loss: 0.2362 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23375\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.1988 - acc: 0.9292 - val_loss: 0.2351 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23375\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.1968 - acc: 0.9290 - val_loss: 0.2364 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.23375\n",
      "Epoch 12/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.1936 - acc: 0.9295 - val_loss: 0.2360 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.23375\n",
      "0.8742661798396335 0.5814810729862422 0.9165133394664213 0.4653902798232695\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.2207 - acc: 0.9317 - val_loss: 0.1804 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18043, saving model to avg-concat-mort_icu-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 15s 967us/step - loss: 0.1766 - acc: 0.9430 - val_loss: 0.1760 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18043 to 0.17596, saving model to avg-concat-mort_icu-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 15s 977us/step - loss: 0.1667 - acc: 0.9446 - val_loss: 0.1771 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17596\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 15s 957us/step - loss: 0.1593 - acc: 0.9455 - val_loss: 0.1738 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17596 to 0.17376, saving model to avg-concat-mort_icu-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 15s 1ms/step - loss: 0.1550 - acc: 0.9478 - val_loss: 0.1742 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17376\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.1495 - acc: 0.9489 - val_loss: 0.1746 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.17376\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.1476 - acc: 0.9500 - val_loss: 0.1745 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17376\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.1442 - acc: 0.9499 - val_loss: 0.1744 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17376\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.1410 - acc: 0.9510 - val_loss: 0.1752 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17376\n",
      "0.8831675172058617 0.5142428181072833 0.9415823367065317 0.4279279279279279\n",
      "Problem type:  los_3\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 14s 940us/step - loss: 0.6904 - acc: 0.6227 - val_loss: 0.6383 - val_acc: 0.6548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63826, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 11s 730us/step - loss: 0.6332 - acc: 0.6585 - val_loss: 0.6277 - val_acc: 0.6659\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63826 to 0.62768, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 10s 663us/step - loss: 0.6187 - acc: 0.6690 - val_loss: 0.6247 - val_acc: 0.6765\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62768 to 0.62474, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 10s 665us/step - loss: 0.6139 - acc: 0.6811 - val_loss: 0.6257 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.62474\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 10s 645us/step - loss: 0.6043 - acc: 0.6857 - val_loss: 0.6224 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.62474 to 0.62236, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 9s 612us/step - loss: 0.6006 - acc: 0.6888 - val_loss: 0.6199 - val_acc: 0.6784\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62236 to 0.61989, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 9s 580us/step - loss: 0.5960 - acc: 0.6918 - val_loss: 0.6210 - val_acc: 0.6802\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61989\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 9s 587us/step - loss: 0.5925 - acc: 0.6977 - val_loss: 0.6211 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.61989\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 9s 596us/step - loss: 0.5889 - acc: 0.7002 - val_loss: 0.6217 - val_acc: 0.6742\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61989\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 9s 585us/step - loss: 0.5872 - acc: 0.7015 - val_loss: 0.6201 - val_acc: 0.6784\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.61989\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 9s 573us/step - loss: 0.5835 - acc: 0.7035 - val_loss: 0.6206 - val_acc: 0.6756\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.61989\n",
      "0.6980265912220049 0.6429630473944931 0.6674333026678932 0.5681003584229389\n",
      "Problem type:  los_7\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 10s 682us/step - loss: 0.3030 - acc: 0.9143 - val_loss: 0.2636 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26362, saving model to avg-concat-los_7-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 9s 575us/step - loss: 0.2589 - acc: 0.9207 - val_loss: 0.2668 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26362\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 9s 570us/step - loss: 0.2504 - acc: 0.9211 - val_loss: 0.2640 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26362\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 9s 569us/step - loss: 0.2450 - acc: 0.9217 - val_loss: 0.2628 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26362 to 0.26282, saving model to avg-concat-los_7-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 9s 572us/step - loss: 0.2404 - acc: 0.9225 - val_loss: 0.2634 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26282\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 9s 570us/step - loss: 0.2373 - acc: 0.9219 - val_loss: 0.2626 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.26282 to 0.26255, saving model to avg-concat-los_7-best_model.hdf5\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 9s 569us/step - loss: 0.2334 - acc: 0.9229 - val_loss: 0.2633 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26255\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 9s 570us/step - loss: 0.2325 - acc: 0.9235 - val_loss: 0.2641 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26255\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 9s 572us/step - loss: 0.2302 - acc: 0.9234 - val_loss: 0.2633 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26255\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 9s 582us/step - loss: 0.2270 - acc: 0.9233 - val_loss: 0.2641 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26255\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 9s 579us/step - loss: 0.2264 - acc: 0.9244 - val_loss: 0.2642 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26255\n",
      "0.7233096811600731 0.220199976512093 0.9188132474701012 0.027548209366391185\n",
      "Hidden unit:  256\n",
      "Embedding:  word2vec\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.2824 - acc: 0.9009 - val_loss: 0.2397 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23965, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 15s 1ms/step - loss: 0.2340 - acc: 0.9175 - val_loss: 0.2294 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23965 to 0.22941, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.2220 - acc: 0.9206 - val_loss: 0.2293 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22941 to 0.22926, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.2111 - acc: 0.9246 - val_loss: 0.2325 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22926\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.2051 - acc: 0.9269 - val_loss: 0.2298 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22926\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.1993 - acc: 0.9269 - val_loss: 0.2282 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.22926 to 0.22820, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.1948 - acc: 0.9294 - val_loss: 0.2292 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.22820\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 20s 1ms/step - loss: 0.1898 - acc: 0.9319 - val_loss: 0.2314 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22820\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.1846 - acc: 0.9305 - val_loss: 0.2345 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.22820\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.1810 - acc: 0.9340 - val_loss: 0.2332 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22820\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 26s 2ms/step - loss: 0.1804 - acc: 0.9342 - val_loss: 0.2357 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.22820\n",
      "0.8753006872852235 0.5798278009766124 0.9162833486660533 0.47246376811594204\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 27s 2ms/step - loss: 0.2061 - acc: 0.9362 - val_loss: 0.1753 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17532, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 23s 1ms/step - loss: 0.1693 - acc: 0.9446 - val_loss: 0.1728 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17532 to 0.17276, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 22s 1ms/step - loss: 0.1581 - acc: 0.9466 - val_loss: 0.1697 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17276 to 0.16967, saving model to avg-word2vec-mort_icu-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.1513 - acc: 0.9496 - val_loss: 0.1714 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16967\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.1449 - acc: 0.9507 - val_loss: 0.1718 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16967\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.1396 - acc: 0.9524 - val_loss: 0.1727 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16967\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.1362 - acc: 0.9534 - val_loss: 0.1734 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16967\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 26s 2ms/step - loss: 0.1309 - acc: 0.9547 - val_loss: 0.1779 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16967\n",
      "0.8878037361299685 0.5265239122471965 0.9429622815087396 0.456140350877193\n",
      "Problem type:  los_3\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 31s 2ms/step - loss: 0.6742 - acc: 0.6171 - val_loss: 0.6265 - val_acc: 0.6677\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62647, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.6272 - acc: 0.6598 - val_loss: 0.6189 - val_acc: 0.6719\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62647 to 0.61891, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.6100 - acc: 0.6776 - val_loss: 0.6197 - val_acc: 0.6659\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.61891\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.5995 - acc: 0.6916 - val_loss: 0.6145 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61891 to 0.61446, saving model to avg-word2vec-los_3-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.5933 - acc: 0.6930 - val_loss: 0.6164 - val_acc: 0.6770\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.61446\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 26s 2ms/step - loss: 0.5862 - acc: 0.6981 - val_loss: 0.6155 - val_acc: 0.6677\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.61446\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 25s 2ms/step - loss: 0.5814 - acc: 0.7066 - val_loss: 0.6166 - val_acc: 0.6724\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61446\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.5754 - acc: 0.7108 - val_loss: 0.6167 - val_acc: 0.6811\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.61446\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.5727 - acc: 0.7134 - val_loss: 0.6176 - val_acc: 0.6779\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61446\n",
      "0.7013270793679567 0.6409345090590508 0.6688132474701012 0.54858934169279\n",
      "Problem type:  los_7\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.2803 - acc: 0.9198 - val_loss: 0.2615 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26154, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 23s 2ms/step - loss: 0.2516 - acc: 0.9215 - val_loss: 0.2590 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26154 to 0.25902, saving model to avg-word2vec-los_7-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 25s 2ms/step - loss: 0.2428 - acc: 0.9226 - val_loss: 0.2613 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25902\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 25s 2ms/step - loss: 0.2371 - acc: 0.9225 - val_loss: 0.2594 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25902\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 26s 2ms/step - loss: 0.2316 - acc: 0.9231 - val_loss: 0.2605 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25902\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 32s 2ms/step - loss: 0.2274 - acc: 0.9241 - val_loss: 0.2611 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25902\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 51s 3ms/step - loss: 0.2246 - acc: 0.9245 - val_loss: 0.2618 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25902\n",
      "0.7272184819076354 0.2201873280088422 0.9176632934682613 0.01648351648351648\n",
      "Embedding:  fasttext\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 37s 2ms/step - loss: 0.2828 - acc: 0.9011 - val_loss: 0.2398 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23978, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 27s 2ms/step - loss: 0.2344 - acc: 0.9173 - val_loss: 0.2422 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23978\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 26s 2ms/step - loss: 0.2226 - acc: 0.9190 - val_loss: 0.2357 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23978 to 0.23565, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.2139 - acc: 0.9235 - val_loss: 0.2377 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23565\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.2060 - acc: 0.9246 - val_loss: 0.2362 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23565\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.2002 - acc: 0.9277 - val_loss: 0.2394 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23565\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.1959 - acc: 0.9307 - val_loss: 0.2375 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23565\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.1912 - acc: 0.9296 - val_loss: 0.2387 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23565\n",
      "0.8751977046435812 0.5781866287151263 0.9181232750689973 0.4764705882352941\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 32s 2ms/step - loss: 0.2223 - acc: 0.9310 - val_loss: 0.1815 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18147, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.1743 - acc: 0.9432 - val_loss: 0.1739 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18147 to 0.17388, saving model to avg-fasttext-mort_icu-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.1627 - acc: 0.9459 - val_loss: 0.1767 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17388\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.1545 - acc: 0.9482 - val_loss: 0.1769 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17388\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.1471 - acc: 0.9503 - val_loss: 0.1742 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17388\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.1427 - acc: 0.9516 - val_loss: 0.1763 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.17388\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 26s 2ms/step - loss: 0.1370 - acc: 0.9527 - val_loss: 0.1774 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17388\n",
      "0.8838779905426285 0.5207405727887269 0.9397424103035878 0.3906976744186047\n",
      "Problem type:  los_3\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 27s 2ms/step - loss: 0.6807 - acc: 0.6196 - val_loss: 0.6317 - val_acc: 0.6659\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63173, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.6276 - acc: 0.6610 - val_loss: 0.6269 - val_acc: 0.6724\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63173 to 0.62685, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.6150 - acc: 0.6726 - val_loss: 0.6217 - val_acc: 0.6738\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62685 to 0.62172, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.6035 - acc: 0.6872 - val_loss: 0.6248 - val_acc: 0.6710\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.62172\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.5957 - acc: 0.6935 - val_loss: 0.6185 - val_acc: 0.6714\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.62172 to 0.61854, saving model to avg-fasttext-los_3-best_model.hdf5\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.5905 - acc: 0.6970 - val_loss: 0.6191 - val_acc: 0.6779\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.61854\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 27s 2ms/step - loss: 0.5866 - acc: 0.7020 - val_loss: 0.6192 - val_acc: 0.6719\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61854\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.5793 - acc: 0.7098 - val_loss: 0.6212 - val_acc: 0.6751\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.61854\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.5769 - acc: 0.7075 - val_loss: 0.6232 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61854\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.5721 - acc: 0.7125 - val_loss: 0.6212 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.61854\n",
      "0.6983955061223257 0.639682257671972 0.6573137074517019 0.534375\n",
      "Problem type:  los_7\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 31s 2ms/step - loss: 0.3187 - acc: 0.9091 - val_loss: 0.2699 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26985, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.2576 - acc: 0.9219 - val_loss: 0.2656 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26985 to 0.26559, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.2475 - acc: 0.9220 - val_loss: 0.2629 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26559 to 0.26291, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.2429 - acc: 0.9231 - val_loss: 0.2607 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26291 to 0.26066, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.2371 - acc: 0.9229 - val_loss: 0.2596 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.26066 to 0.25960, saving model to avg-fasttext-los_7-best_model.hdf5\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.2333 - acc: 0.9249 - val_loss: 0.2623 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25960\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.2297 - acc: 0.9240 - val_loss: 0.2601 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25960\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.2260 - acc: 0.9243 - val_loss: 0.2603 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25960\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.2231 - acc: 0.9258 - val_loss: 0.2610 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25960\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 35s 2ms/step - loss: 0.2193 - acc: 0.9258 - val_loss: 0.2609 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25960\n",
      "0.7232540924545721 0.227313046327572 0.9188132474701012 0.05361930294906167\n",
      "Embedding:  concat\n",
      "=============================\n",
      "Iteration number:  1\n",
      "Problem type:  mort_hosp\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 34s 2ms/step - loss: 0.2900 - acc: 0.9011 - val_loss: 0.2400 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23996, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.2369 - acc: 0.9163 - val_loss: 0.2337 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23996 to 0.23366, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.2203 - acc: 0.9205 - val_loss: 0.2329 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23366 to 0.23289, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 30s 2ms/step - loss: 0.2115 - acc: 0.9230 - val_loss: 0.2337 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23289\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.2045 - acc: 0.9253 - val_loss: 0.2316 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23289 to 0.23160, saving model to avg-concat-mort_hosp-best_model.hdf5\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 28s 2ms/step - loss: 0.2005 - acc: 0.9269 - val_loss: 0.2352 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23160\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.1934 - acc: 0.9296 - val_loss: 0.2344 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23160\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 33s 2ms/step - loss: 0.1879 - acc: 0.9325 - val_loss: 0.2377 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23160\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 31s 2ms/step - loss: 0.1835 - acc: 0.9315 - val_loss: 0.2393 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23160\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 32s 2ms/step - loss: 0.1810 - acc: 0.9332 - val_loss: 0.2401 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23160\n",
      "0.8732834390695214 0.5755251575977121 0.9149034038638455 0.45588235294117646\n",
      "Problem type:  mort_icu\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 31s 2ms/step - loss: 0.2145 - acc: 0.9334 - val_loss: 0.1793 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17927, saving model to avg-concat-mort_icu-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.1726 - acc: 0.9434 - val_loss: 0.1741 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17927 to 0.17412, saving model to avg-concat-mort_icu-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.1612 - acc: 0.9460 - val_loss: 0.1732 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17412 to 0.17322, saving model to avg-concat-mort_icu-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 29s 2ms/step - loss: 0.1498 - acc: 0.9494 - val_loss: 0.1765 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17322\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 32s 2ms/step - loss: 0.1438 - acc: 0.9508 - val_loss: 0.1759 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17322\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 34s 2ms/step - loss: 0.1386 - acc: 0.9528 - val_loss: 0.1760 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.17322\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 35s 2ms/step - loss: 0.1337 - acc: 0.9541 - val_loss: 0.1811 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17322\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 32s 2ms/step - loss: 0.1291 - acc: 0.9573 - val_loss: 0.1789 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17322\n",
      "0.8767990074441687 0.514721842496544 0.9411223551057958 0.4285714285714286\n",
      "Problem type:  los_3\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.6944 - acc: 0.6176 - val_loss: 0.6416 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64161, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.6278 - acc: 0.6636 - val_loss: 0.6281 - val_acc: 0.6659\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.64161 to 0.62809, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.6129 - acc: 0.6736 - val_loss: 0.6252 - val_acc: 0.6650\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62809 to 0.62519, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 18s 1ms/step - loss: 0.6010 - acc: 0.6879 - val_loss: 0.6248 - val_acc: 0.6682\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62519 to 0.62484, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 18s 1ms/step - loss: 0.5917 - acc: 0.6954 - val_loss: 0.6240 - val_acc: 0.6710\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.62484 to 0.62398, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 18s 1ms/step - loss: 0.5848 - acc: 0.7038 - val_loss: 0.6237 - val_acc: 0.6724\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62398 to 0.62369, saving model to avg-concat-los_3-best_model.hdf5\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 18s 1ms/step - loss: 0.5809 - acc: 0.7049 - val_loss: 0.6252 - val_acc: 0.6710\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.62369\n",
      "Epoch 8/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.5742 - acc: 0.7115 - val_loss: 0.6254 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.62369\n",
      "Epoch 9/100\n",
      "15219/15219 [==============================] - 20s 1ms/step - loss: 0.5711 - acc: 0.7120 - val_loss: 0.6269 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.62369\n",
      "Epoch 10/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.5646 - acc: 0.7189 - val_loss: 0.6261 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.62369\n",
      "Epoch 11/100\n",
      "15219/15219 [==============================] - 18s 1ms/step - loss: 0.5617 - acc: 0.7203 - val_loss: 0.6285 - val_acc: 0.6594\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.62369\n",
      "0.7025885546822734 0.6435931482098729 0.6665133394664213 0.577259475218659\n",
      "Problem type:  los_7\n",
      "__________________\n",
      "Train on 15219 samples, validate on 2164 samples\n",
      "Epoch 1/100\n",
      "15219/15219 [==============================] - 18s 1ms/step - loss: 0.3163 - acc: 0.9103 - val_loss: 0.2718 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27185, saving model to avg-concat-los_7-best_model.hdf5\n",
      "Epoch 2/100\n",
      "15219/15219 [==============================] - 16s 1ms/step - loss: 0.2607 - acc: 0.9210 - val_loss: 0.2671 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27185 to 0.26714, saving model to avg-concat-los_7-best_model.hdf5\n",
      "Epoch 3/100\n",
      "15219/15219 [==============================] - 17s 1ms/step - loss: 0.2475 - acc: 0.9220 - val_loss: 0.2716 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26714\n",
      "Epoch 4/100\n",
      "15219/15219 [==============================] - 19s 1ms/step - loss: 0.2420 - acc: 0.9228 - val_loss: 0.2684 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26714\n",
      "Epoch 5/100\n",
      "15219/15219 [==============================] - 21s 1ms/step - loss: 0.2366 - acc: 0.9235 - val_loss: 0.2685 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26714\n",
      "Epoch 6/100\n",
      "15219/15219 [==============================] - 24s 2ms/step - loss: 0.2304 - acc: 0.9244 - val_loss: 0.2699 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26714\n",
      "Epoch 7/100\n",
      "15219/15219 [==============================] - 27s 2ms/step - loss: 0.2279 - acc: 0.9238 - val_loss: 0.2695 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26714\n",
      "0.7137266105244195 0.20490147180395715 0.9169733210671573 0.01634877384196185\n"
     ]
    }
   ],
   "source": [
    "embedding_types = ['word2vec', 'fasttext', 'concat']\n",
    "\n",
    "embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
    "\n",
    "target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
    "\n",
    "\n",
    "num_epoch = 100\n",
    "model_patience = 5\n",
    "monitor_criteria = 'val_loss'\n",
    "batch_size = 64\n",
    "iter_num = 2\n",
    "unit_sizes = [128, 256]\n",
    "\n",
    "#layers = [\"LSTM\", \"GRU\"]\n",
    "layers = [\"GRU\"]\n",
    "for each_layer in layers:\n",
    "    print (\"Layer: \", each_layer)\n",
    "    for each_unit_size in unit_sizes:\n",
    "        print (\"Hidden unit: \", each_unit_size)\n",
    "\n",
    "        for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n",
    "            print (\"Embedding: \", embed_name)\n",
    "            print(\"=============================\")\n",
    "\n",
    "            temp_train_ner = dict((k, embed_dict[k]) for k in train_ids)\n",
    "            temp_dev_ner = dict((k, embed_dict[k]) for k in dev_ids)\n",
    "            temp_test_ner = dict((k, embed_dict[k]) for k in test_ids)\n",
    "\n",
    "            x_train_ner = create_dataset(temp_train_ner)\n",
    "            x_dev_ner = create_dataset(temp_dev_ner)\n",
    "            x_test_ner = create_dataset(temp_test_ner)\n",
    "\n",
    "\n",
    "            for iteration in range(1, iter_num):\n",
    "                print (\"Iteration number: \", iteration)\n",
    "\n",
    "                for each_problem in target_problems:\n",
    "                    print (\"Problem type: \", each_problem)\n",
    "                    print (\"__________________\")\n",
    "\n",
    "                    early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "                    best_model_name = \"avg-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n",
    "                    checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1,\n",
    "                        save_best_only=True, mode='min', period=1)\n",
    "\n",
    "\n",
    "                    callbacks = [early_stopping_monitor, checkpoint]\n",
    "\n",
    "                    model = avg_ner_model(each_layer, each_unit_size, embed_name)\n",
    "                    \n",
    "                    model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n",
    "                              validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, \n",
    "                              batch_size=batch_size )\n",
    "\n",
    "                    model.load_weights(best_model_name)\n",
    "\n",
    "                    probs, predictions = make_prediction_multi_avg(model, [x_test_lstm, x_test_ner])\n",
    "                    \n",
    "                    save_scores_multi_avg(predictions, probs, y_test[each_problem], \n",
    "                               embed_name, each_problem, iteration, each_unit_size, \n",
    "                               each_layer, type_of_ner)\n",
    "                    \n",
    "                    reset_keras(model)\n",
    "                    #del model\n",
    "                    # clear_session()\n",
    "                    # gc.collect()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aac8dec30b2392ddea3a2b04b3b1a1a9ab9ac95d8d7217d56add55303069cbca"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
